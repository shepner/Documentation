{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this application is to publish the YAML formatted documents\n",
    "\n",
    "Output formats:\n",
    "\n",
    "* Pandoc\n",
    "* HTML\n",
    "* <s>PDF</s>\n",
    "* CommonMark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "\n",
    "References\n",
    "\n",
    "* [PyYAML](https://pyyaml.org/)\n",
    "* [pandoc](https://pandoc.org/)\n",
    "  * [TeX Live](https://www.tug.org/texlive/) which is needed to [create a PDF](https://pandoc.org/MANUAL.html#creating-a-pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install\n",
    "\n",
    "Anything that needs installed to use this should be listed here\n",
    "\n",
    "``` shell\n",
    "#PyYAML\n",
    "sudo -H pip3 install pyyaml\n",
    "\n",
    "#Pandoc\n",
    "sudo apt install pandoc\n",
    "sudo apt install texlive-latex-recommended\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#these are the base dirs everthing works from:\n",
    "srcDir=\"./src\"\n",
    "dstDir=\"./docs\"\n",
    "\n",
    "#The node names are based on the [Pandoc Supported Formats](https://github.com/tajmone/markdown-guide/tree/master/pandoc#pandoc-supported-formats)\n",
    "#the `dstPath` likely could go away as it was based upon a different idea for how the files should be stored\n",
    "#this is a dictionary of dictionaries.  To access data: `outputConfig['yaml']['ext']`\n",
    "outputConfig = {\n",
    "    'yaml': {\n",
    "        'ext': '.yaml', \n",
    "        'dstPath': dstDir\n",
    "    },\n",
    "    'markdown': { #Pandoc MarkDown varient\n",
    "        'ext': '.pandoc', \n",
    "        'dstPath': dstDir\n",
    "    },\n",
    "    'markdown_strict': { #CommonMark spec\n",
    "        'ext': '.md', \n",
    "        'dstPath': dstDir\n",
    "    },\n",
    "    'html5': {\n",
    "        'ext': '.html', \n",
    "        'dstPath': dstDir\n",
    "    },\n",
    "    'pdf': {\n",
    "        'ext': '.pdf', \n",
    "        'dstPath': dstDir\n",
    "    }\n",
    "}\n",
    "#outputConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#find files that match the pattern\n",
    "\n",
    "#these functions came from:\n",
    "#https://stackoverflow.com/questions/1724693/find-a-file-in-python\n",
    "\n",
    "\"\"\"\n",
    "#this will find the first match\n",
    "import os\n",
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)\n",
    "\n",
    "#this will find all matches\n",
    "import os\n",
    "def find_all(name, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "#this will match a pattern with wildcards\n",
    "\"\"\"\n",
    "import os, fnmatch\n",
    "def find(pattern, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            print (name)\n",
    "            if fnmatch.fnmatch(name, pattern): #this supports wildcards\n",
    "                result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\"\"\"\n",
    "#this just does a substring match\n",
    "\"\"\"\n",
    "import os\n",
    "def find(pattern, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        #print (root, dirs, files, '\\n')\n",
    "        for file in files:\n",
    "            name = os.path.join(root, file)\n",
    "            if pattern in name: #this is exact substring match\n",
    "                #print (name)\n",
    "                result.append(name)\n",
    "    return result\n",
    "\"\"\"\n",
    "#this gives full regex\n",
    "import os, re\n",
    "def find(pattern, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        #print (root, dirs, files, '\\n')\n",
    "        for file in files:\n",
    "            name = os.path.join(root, file)\n",
    "            m = re.search (pattern, name) \n",
    "            if m: \n",
    "                #print (name)\n",
    "                result.append(name)\n",
    "    return result\n",
    "\n",
    "#find('*.txt', '/path/to/dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def findDir(pattern, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        #print (root, dirs, files, '\\n')\n",
    "        if pattern in root: #this is exact substring match\n",
    "            #print (root)\n",
    "            result.append(root)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mkdir_p() and safe_open_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#the following is from:\n",
    "#https://stackoverflow.com/questions/23793987/write-file-to-a-directory-that-doesnt-exist\n",
    "\n",
    "import os, os.path\n",
    "import errno\n",
    "\n",
    "# Taken from https://stackoverflow.com/a/600612/119527\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else: raise\n",
    "\n",
    "def safe_open_w(path):\n",
    "    ''' Open \"path\" for writing, creating any parent directories as needed.\n",
    "    '''\n",
    "    mkdir_p(os.path.dirname(path))\n",
    "    return open(path, 'w')\n",
    "\n",
    "#with safe_open_w('/Users/bill/output/output-text.txt') as f:\n",
    "#    f.write(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yaml2python()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#this will convert a yaml file to a python data structure.\n",
    "\n",
    "import yaml\n",
    "\n",
    "def yaml2python (file):\n",
    "    #print (file)\n",
    "\n",
    "    f = open (file, 'r') #open the file to read\n",
    "    content = yaml.load(f.read(), Loader=yaml.FullLoader) #convert the yaml contents into a python data structure\n",
    "    f.close() #close the file\n",
    "    \n",
    "    #print (content)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_valid_uuid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#From:  https://stackoverflow.com/questions/19989481/how-to-determine-if-a-string-is-a-valid-v4-uuid\n",
    "\n",
    "from uuid import UUID\n",
    "\n",
    "def is_valid_uuid(uuid_to_test, version=4):\n",
    "    \"\"\"\n",
    "    Check if uuid_to_test is a valid UUID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    uuid_to_test : str\n",
    "    version : {1, 2, 3, 4}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `True` if uuid_to_test is a valid UUID, otherwise `False`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> is_valid_uuid('c9bf9e57-1685-4c89-bafb-ff5af830be8a')\n",
    "    True\n",
    "    >>> is_valid_uuid('c9bf9e58')\n",
    "    False\n",
    "    \"\"\"\n",
    "    try:\n",
    "        uuid_obj = UUID(uuid_to_test, version=version)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "    return str(uuid_obj) == uuid_to_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generateDocumentBody()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#look for MD header levels and increase them by the indicated amount\n",
    "import re\n",
    "def increaseHeaderLevel (mdText, addlLevels):\n",
    "    if addlLevels > 0:\n",
    "        string = \"#\"\n",
    "        \n",
    "        #add the appropriate number of `#`s to the string\n",
    "        x = 1\n",
    "        while x < addlLevels:\n",
    "            string = string + '#'\n",
    "            x += 1\n",
    "            \n",
    "        mdText = re.sub ('^#', string, mdText, flags=re.MULTILINE) #substitute the old string with the new one\n",
    "    return (mdText)\n",
    "\n",
    "#################################################\n",
    "#walk and print the tree within documentBody\n",
    "# results    : the data to be returned\n",
    "# srcData    : the source data\n",
    "# docID      : the UUID of the document\n",
    "# depth      : how many header levels to add\n",
    "import re\n",
    "def generateDocumentBody (srcData, docID, depth):\n",
    "    results = \"\"\n",
    "    \n",
    "    if isinstance(srcData, list):\n",
    "        print ('List detected')\n",
    "        \n",
    "        dirList = findDir(docID, './src')\n",
    "        #print (dirList)\n",
    "        \n",
    "        for element in srcData:\n",
    "            if isinstance(element, list) or isinstance(element, dict):\n",
    "                print ('Structure detected')\n",
    "                #walk the next level down and increase the header depth\n",
    "                results += generateDocumentBody (element, docID, depth+1)\n",
    "                \n",
    "            #elif '.md' in element:\n",
    "            elif re.search('.md$', element, flags=re.IGNORECASE):\n",
    "                print ('markdown: ' + element)\n",
    "\n",
    "                #read in the content\n",
    "                fnameList = find (element, dirList[0]) #search for the file in this doc's dir tree\n",
    "                \n",
    "                if len(fnameList) == 0:\n",
    "                    print ('no files found')\n",
    "                    continue #skip to the next file\n",
    "                    \n",
    "                print (fnameList)\n",
    "                try:\n",
    "                    f = open (fnameList[0], 'r')\n",
    "                    #read in the MD file.  Search for all `#` headers and decrease them as indicated by `indent`\n",
    "                    results += increaseHeaderLevel (f.read(), depth)\n",
    "                    f.close()\n",
    "                except OSError:\n",
    "                    print (\"Could not open/read file:\", fnameList[0])\n",
    "                    #sys.exit()\n",
    "                    \n",
    "            #elif '.yaml' in element:\n",
    "            elif re.search('.yaml$', element, flags=re.IGNORECASE):\n",
    "                print ('YAML: ' + element)\n",
    "                #process the file\n",
    "            elif is_valid_uuid(element):\n",
    "                print ('UUIDv4: ' + element)\n",
    "                #go find the file and then process the file\n",
    "            else: #No idea what this is. Assuming its MD text\n",
    "                print ('unknown: ' + element)\n",
    "                results += element #assuming that if you are manually entering MD then you can control the formatting too\n",
    "            results += '\\n\\n'\n",
    "            \n",
    "    elif isinstance(srcData, dict):\n",
    "        print ('Dict detected')\n",
    "        \n",
    "    else:\n",
    "        #print ('markdown:  no structure')\n",
    "        results += srcData\n",
    "        \n",
    "    results += '\\n\\n'\n",
    "    return (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generatePandocContents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#the pandoc file is the 'universal' format that all others will be generated from\n",
    "#`data` = the full python data structure object\n",
    "\n",
    "def generatePandocContents (data):\n",
    "    document = \"\" #start with a blank document\n",
    "    \n",
    "    #################################################\n",
    "    #Pandoc’s Markdown [Metadata blocks](https://pandoc.org/MANUAL.html#metadata-blocks)\n",
    "    #Extension: pandoc_title_block\n",
    "    \n",
    "    keys=[\n",
    "        \"title\",\n",
    "        \"author\" #pretending that author will never be more then 1 entry\n",
    "    ]\n",
    "    for key in keys:\n",
    "        if data.get(key) != None: #from [here](https://thispointer.com/python-how-to-check-if-a-key-exists-in-dictionary/)\n",
    "            document += '% ' + data[key] + '\\n'\n",
    "    \n",
    "    date=\"\"\n",
    "    for element in data['revision']:  #step through the list elements\n",
    "        #print (element['date'])\n",
    "        if date < element['date']: #REPLACE THIS with something that understands full ISO date/time formatted data!\n",
    "            date = element['date']\n",
    "    document += '% ' + date + '\\n' #output the final result\n",
    "    \n",
    "    #################################################\n",
    "    #Pandoc’s Markdown [Metadata blocks](https://pandoc.org/MANUAL.html#metadata-blocks)\n",
    "    #Extension: yaml_metadata_block\n",
    "\n",
    "    # not entirely sure if this replaces the title block or not\n",
    "    \n",
    "    document += \"\\n\" #pandoc expects a blank line before this section\n",
    "    document += \"---\\n\" #this is required to start the yaml metadata block\n",
    "    #dump the following info:\n",
    "    keys=[\n",
    "        \"title\",\n",
    "        \"author\",\n",
    "        \"abstract\",\n",
    "        \"lang\"\n",
    "    ]\n",
    "    for key in keys:\n",
    "        if data.get(key) != None: #from [here](https://thispointer.com/python-how-to-check-if-a-key-exists-in-dictionary/)\n",
    "            document += '\"' + key + '\": ' + yaml.dump(data[key], default_style='\"') #output format: `\"key\": \"value\"\\n`\n",
    "    \n",
    "    # need to deal with \"keywords\" specifically    \n",
    "    \n",
    "    document += \"...\\n\\n\" #this is required to end the yaml metadata block\n",
    "\n",
    "    #################################################\n",
    "    \n",
    "    document = generateDocumentBody (data['body'], data['id'], 0) #work through the possible formats and correctly print\n",
    "    \n",
    "    document += \"\\n\"\n",
    "    \n",
    "    #################################################\n",
    "    \n",
    "    #print the revisions as a table in HTML because CommonMark doesnt do that\n",
    "    document += \"---\\n\\n\"\n",
    "    document += \"# Revision history\\n\\n\"\n",
    "    \n",
    "    #table style\n",
    "    document += \"<style>\\n\"\n",
    "    document += \"table { border-collapse: collapse; width: 100%; }\\n\"\n",
    "    document += \"td, th { border: 1px solid #dddddd; text-align: left; padding: 8px; }\\n\"\n",
    "    document += \"</style>\\n\"\n",
    "    document += \"\\n\"\n",
    "    \n",
    "    #Table layout:  \"date\", \"status\", \"name\", \"reason\"\n",
    "    document += \"<table>\\n\"\n",
    "    document += \"<tr>\\n\"\n",
    "    document += \"<th>Date</th>\\n\"\n",
    "    document += \"<th>Name</th>\\n\"\n",
    "    document += \"<th>Reason</th>\\n\"\n",
    "    document += \"</tr>\\n\"\n",
    "    #the 'revisions' key consists of a list of sets\n",
    "    #`content['revision'][0]['date']` will provide that specific data element\n",
    "    for element in data['revision']:  #step through the list elements\n",
    "        document += \"<tr>\\n\"\n",
    "        #now print the fields\n",
    "        document += \"<td>\" + element['date'] + \"</td>\\n\"\n",
    "        document += \"<td>\" + element['name'] + \"</td>\\n\"\n",
    "        document += \"<td>\" + element['reason'] + \"</td>\\n\"\n",
    "        document += \"</tr>\\n\"\n",
    "    document += \"</table>\\n\"\n",
    "    \n",
    "    #################################################\n",
    "    #we are done generating the document contents\n",
    "    \n",
    "    #print (document)\n",
    "    return (document)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert2format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#convert the pandoc formatted text into the specified format\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def convert2format(srcFile, dstFile, outputFormat):\n",
    "    if (outputFormat == 'html5') or (outputFormat == 'markdown_strict'):\n",
    "        #subprocess.run(['pandoc', content['id']+'.pandoc', '--html-q-tags', '-s', '-o', content['id']+'.html'])\n",
    "        subprocess.run(['pandoc', srcFile, '-s', '--html-q-tags', '-f', 'markdown+yaml_metadata_block+pandoc_title_block', '-t', outputFormat, '-o', dstFile])\n",
    "    elif outputFormat == 'pdf':\n",
    "        pass #the pdf conversion is generating font errors\n",
    "        #print ('Error:  PDF format is currently broken')\n",
    "        #subprocess.run(['pandoc', srcFile, '-s', '--html-q-tags', '-t', outputFormat, '-o', dstFile])\n",
    "    elif (outputFormat != 'markdown') and (outputFormat != 'yaml'): #error on all but these which we will quietly ignore\n",
    "        print ('Error:  ' + outputFormat + ' is not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the files that need to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#look for all the yaml files\n",
    "\n",
    "#srcFiles = find('*' + outputConfig['yaml']['ext'], srcDir)\n",
    "srcFiles = find(outputConfig['yaml']['ext'], srcDir)\n",
    "#srcFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process each file\n",
    "\n",
    "For simplicity, this is using the premise that each YAML document is compiled to an output dir based upon its ID.  The reason for this is to avoid orphan files from accumulating.  At some later point, the process should look for only what changed and adjust the specific destination dir accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the document summary data structure:\n",
    "\n",
    "``` python\n",
    "summaryDataDemo = {\n",
    "    'type': { #`type` field: key index\n",
    "        '1928374': { #`id` field: key index\n",
    "            'title': 'text',\n",
    "            'shortDescription': 'text',\n",
    "            'url': {\n",
    "                'html5': 'http://',\n",
    "                'pdf': 'http://',\n",
    "                'yaml': 'http://',\n",
    "                'markdown': 'http://',\n",
    "                'markdown_strict': 'http://'\n",
    "            },\n",
    "            'path': {\n",
    "                'yaml': './dir/file.yaml'\n",
    "            },\n",
    "        },\n",
    "        '9898472': { #`id` field: key index\n",
    "            'title': 'text',\n",
    "            'shortDescription': 'text',\n",
    "            'url': {\n",
    "                'html5': 'http://',\n",
    "                'pdf': 'http://',\n",
    "                'yaml': 'http://',\n",
    "                'markdown': 'http://',\n",
    "                'markdown_strict': 'http://'\n",
    "            },\n",
    "            'path': {\n",
    "                'yaml': './dir/file.yaml'\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "summaryDataDemo['type']['1928374']['url']['html5']\n",
    "\n",
    "import yaml\n",
    "print (yaml.dump(summaryDataDemo))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./src/32f2e7dc-0d00-4bd9-b39f-9d5b562f8415.yaml\n",
      "./src/ad9c7149-fa91-4e62-a86b-fdc4387840d1.yaml\n",
      "./src/1e7c647e-93d7-455d-b5a5-fd7205ca1b14.yaml\n",
      "./src/cd498dae-9287-4432-91a3-97adf1ea4dd6.yaml\n",
      "./src/c54c285f-eeb4-4a42-815f-9ea0656265e2.yaml\n",
      "./src/ebd4a2a1-1c57-4dfb-b13b-c02355a40d74.yaml\n",
      "./src/4480c89d-1da0-4f18-9f8b-f0238333e69a.yaml\n",
      "./src/93a0be83-8e5a-4a46-b264-218646b412ce.yaml\n",
      "./src/320af541-073e-4d76-ab49-d6db5991b48b/320af541-073e-4d76-ab49-d6db5991b48b.yaml\n",
      "List detected\n",
      "unknown: # placeholder text here\n",
      "Structure detected\n",
      "List detected\n",
      "unknown: ## Mission\n",
      "markdown: 320af541-073e-4d76-ab49-d6db5991b48b/ServiceCatalog.md\n",
      "['./src/320af541-073e-4d76-ab49-d6db5991b48b/ServiceCatalog.md']\n",
      "unknown: ## Responsibility and procedures\n",
      "Structure detected\n",
      "List detected\n",
      "markdown: /OrgStructure.md\n",
      "['./src/320af541-073e-4d76-ab49-d6db5991b48b/OrgStructure.md']\n",
      "markdown: ./Procedure.md\n",
      "['./src/320af541-073e-4d76-ab49-d6db5991b48b/Procedure.md']\n",
      "markdown: /Recovery.md\n",
      "['./src/320af541-073e-4d76-ab49-d6db5991b48b/Recovery.md']\n",
      "markdown: /Escalation.md\n",
      "no files found\n",
      "markdown: /Review.md\n",
      "['./src/320af541-073e-4d76-ab49-d6db5991b48b/Review.md']\n",
      "Structure detected\n",
      "List detected\n",
      "markdown: /Reporting.md\n",
      "['./src/320af541-073e-4d76-ab49-d6db5991b48b/Reporting.md']\n",
      "markdown: /EvidenceCollection.md\n",
      "['./src/320af541-073e-4d76-ab49-d6db5991b48b/EvidenceCollection.md']\n",
      "markdown: /Compliance.md\n",
      "no files found\n",
      "./src/4a4d6ec7-4cce-45f8-aa79-df1764058818/4a4d6ec7-4cce-45f8-aa79-df1764058818.yaml\n"
     ]
    }
   ],
   "source": [
    "#delete the output dir tree before regenerating\n",
    "\n",
    "summaryData = {} #start out with a blank dataset\n",
    "\n",
    "#generate files\n",
    "for file in srcFiles:\n",
    "    if '.ipynb_checkpoints' in file: #Jupyter leaves these all over the place\n",
    "        #print ('Skipping: ' + file)\n",
    "        continue #goto the next file\n",
    "    \n",
    "    print (file)\n",
    "\n",
    "    #read the file and convert it to a python data structure\n",
    "    content = yaml2python (file)\n",
    "    #print (content)\n",
    "    \n",
    "    #################################################\n",
    "    \n",
    "    #one dir structure per file\n",
    "    outputDir = outputConfig['markdown']['dstPath'] + \"/\" + content['id']\n",
    "    pandocFile = outputDir + \"/\" + content['id'] + outputConfig['markdown']['ext']\n",
    " \n",
    "    pandocContents = generatePandocContents (content)\n",
    "    #print (output)\n",
    "       \n",
    "    #save the document to file\n",
    "    f = safe_open_w(pandocFile) #create the path if needed and open a file for output\n",
    "    f.write(pandocContents) #write the data to file\n",
    "    f.close()  #close the file\n",
    "    \n",
    "    #do the format conversions\n",
    "    for outputFormat in outputConfig:\n",
    "        \n",
    "        #construct the full destination file/path\n",
    "        outputFile = outputDir + \"/\" + content['id'] + outputConfig[outputFormat]['ext']\n",
    "        #print (outputFile)\n",
    "        \n",
    "        convert2format(pandocFile, outputFile, outputFormat)\n",
    "        \n",
    "    #################################################\n",
    "    #save data that will be used for the summary\n",
    "\n",
    "    if summaryData.get(content['type']) == None:\n",
    "        summaryData.update({content['type'] : {}})\n",
    "\n",
    "    if summaryData[content['type']].get(content['id']) == None:\n",
    "        summaryData[content['type']].update({content['id'] : {}})\n",
    "\n",
    "    if summaryData[content['type']][content['id']].get('title') == None:\n",
    "        summaryData[content['type']][content['id']].update({'title' : content['title']})\n",
    "        \n",
    "    if summaryData[content['type']][content['id']].get('abstract') == None:\n",
    "        summaryData[content['type']][content['id']].update({'abstract' : content['abstract']})\n",
    "        \n",
    "    if summaryData[content['type']][content['id']].get('url') == None:\n",
    "        summaryData[content['type']][content['id']].update({'url' : {}})\n",
    "    \n",
    "    for outputFormat in outputConfig:\n",
    "        if outputFormat == 'yaml':\n",
    "            continue #skip to the next element in the loop\n",
    "        #this is the relative url for the file\n",
    "        url = '/Documentation/' + content['id'] + '/' + content['id'] + outputConfig[outputFormat]['ext']\n",
    "        if summaryData[content['type']][content['id']]['url'].get(outputFormat) == None:\n",
    "            summaryData[content['type']][content['id']]['url'].update({outputFormat : url})\n",
    "    \n",
    "    if summaryData[content['type']][content['id']].get('path') == None:\n",
    "        summaryData[content['type']][content['id']].update({'path' : {}})\n",
    "            \n",
    "    if summaryData[content['type']][content['id']]['path'].get('yaml') == None:\n",
    "        summaryData[content['type']][content['id']]['path'].update({'yaml' : file})\n",
    "    \n",
    "    \n",
    "#summaryData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#group by doc type\n",
    "#title ([YAML] [pandoc] [md] [html] [pdf]): shortDescription\n",
    "document = \"\"\n",
    "\n",
    "document += '---\\n'\n",
    "document += '\"title\": \"Document index\"\\n'\n",
    "document += '\"lang\": \"en\"\\n'\n",
    "document += '...\\n\\n'\n",
    "\n",
    "for el1 in summaryData: #type\n",
    "    #print (el1)\n",
    "    document += el1 + '\\n\\n'\n",
    "    \n",
    "    for el2 in summaryData[el1]: #id\n",
    "        #print (\"  \" + el2)\n",
    "        \n",
    "        document += '* [' + summaryData[el1][el2]['title'] + '](' + summaryData[el1][el2]['url']['html5'] + ') '\n",
    "\n",
    "        document += '[(Pandoc)](' + summaryData[el1][el2]['url']['markdown'] + ') '\n",
    "        document += '[(MarkDown)](' + summaryData[el1][el2]['url']['markdown_strict'] + ') '\n",
    "        \n",
    "        if summaryData[el1][el2]['abstract'] != None:\n",
    "            document += summaryData[el1][el2]['abstract']\n",
    "            \n",
    "        document += '\\n'\n",
    "        \n",
    "    document += '\\n'\n",
    "\n",
    "#print (document)\n",
    "\n",
    "#save the file\n",
    "mdFile = dstDir + \"/index.pandoc\"\n",
    "f = safe_open_w(mdFile) #create the path if needed and open a file for output\n",
    "f.write(document) #write the data to file\n",
    "f.close()  #close the file\n",
    "\n",
    "#convert to html\n",
    "convert2format(mdFile, dstDir + \"/index.html\", 'html5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate list of source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#group by doc type\n",
    "#title ([YAML] [pandoc] [md] [html] [pdf]): shortDescription\n",
    "document = \"\"\n",
    "\n",
    "for el1 in summaryData: #type\n",
    "    #print (el1)\n",
    "    document += el1 + '\\n\\n'\n",
    "    \n",
    "    for el2 in summaryData[el1]: #id\n",
    "        #print (\"  \" + el2)\n",
    "        \n",
    "        document += '* [' + summaryData[el1][el2]['title'] + '](' + summaryData[el1][el2]['path']['yaml'] + ') '\n",
    "        \n",
    "        if summaryData[el1][el2]['abstract'] != None:\n",
    "            document += summaryData[el1][el2]['abstract']\n",
    "            \n",
    "        document += '\\n'\n",
    "        \n",
    "    document += '\\n'\n",
    "\n",
    "#print (document)\n",
    "\n",
    "#save the file\n",
    "mdFile = \"./README.md\"\n",
    "f = safe_open_w(mdFile) #create the path if needed and open a file for output\n",
    "f.write(document) #write the data to file\n",
    "f.close()  #close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
