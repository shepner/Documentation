{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this assumes that\n",
    "* aws credentials have been previously setup\n",
    "* Boto3 has been installed:  `pip3 install boto3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_bucket(bucket_name, s3_resource)\n",
    "\n",
    "`bucket_create_response = create_bucket(bucket_name, s3_resource)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, s3_resource):\n",
    "    return s3_resource.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## searching for files\n",
    "\n",
    "`get_matching_s3_objects(bucket, prefix=\"\", suffix=\"\")`\n",
    "\n",
    "`key = get_matching_s3_keys(bucket, prefix=\"\", suffix=\"\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#https://alexwlchan.net/2017/07/listing-s3-keys/\n",
    "#https://alexwlchan.net/2019/07/listing-s3-keys/\n",
    "\n",
    "import boto3\n",
    "\n",
    "def get_matching_s3_objects(bucket, prefix=\"\", suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Generate objects in an S3 bucket.\n",
    "\n",
    "    :param bucket: Name of the S3 bucket.\n",
    "    :param prefix: Only fetch objects whose key starts with\n",
    "        this prefix (optional).\n",
    "    :param suffix: Only fetch objects whose keys end with\n",
    "        this suffix (optional).\n",
    "    \"\"\"\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "    kwargs = {'Bucket': bucket}\n",
    "\n",
    "    # We can pass the prefix directly to the S3 API.  If the user has passed\n",
    "    # a tuple or list of prefixes, we go through them one by one.\n",
    "    if isinstance(prefix, str):\n",
    "        prefixes = (prefix, )\n",
    "    else:\n",
    "        prefixes = prefix\n",
    "\n",
    "    for key_prefix in prefixes:\n",
    "        kwargs[\"Prefix\"] = key_prefix\n",
    "\n",
    "        for page in paginator.paginate(**kwargs):\n",
    "            try:\n",
    "                contents = page[\"Contents\"]\n",
    "            except KeyError:\n",
    "                return\n",
    "\n",
    "            for obj in contents:\n",
    "                key = obj[\"Key\"]\n",
    "                if key.endswith(suffix):\n",
    "                    yield obj\n",
    "\n",
    "\n",
    "def get_matching_s3_keys(bucket, prefix=\"\", suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Generate the keys in an S3 bucket.\n",
    "\n",
    "    :param bucket: Name of the S3 bucket.\n",
    "    :param prefix: Only fetch keys that start with this prefix (optional).\n",
    "    :param suffix: Only fetch keys that end with this suffix (optional).\n",
    "    \"\"\"\n",
    "    for obj in get_matching_s3_objects(bucket, prefix, suffix):\n",
    "        yield obj[\"Key\"]\n",
    "\n",
    "#for key in get_matching_s3_keys(bucket='testname.asyla.org', prefix='BlueMarble/', suffix='.jpg'):\n",
    "#    print(key)\n",
    "#print('\\n\\n')\n",
    "#for key in get_matching_s3_keys(bucket='testname.asyla.org', suffix=('.jpg', '.JPG')):\n",
    "#    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## does_key_exist(bucket_name, file_name)\n",
    "\n",
    "`boolean = does_key_exist(bucket_name, file_name)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/33842944/check-if-a-key-exists-in-a-bucket-in-s3-using-boto3\n",
    "\n",
    "def does_key_exist(bucket_name, file_name):\n",
    "    try:\n",
    "        s3.Object(bucket_name, file_name).load()\n",
    "    except:\n",
    "        #print ('error')\n",
    "        return (False)\n",
    "    else:\n",
    "        #print ('worked')\n",
    "        return (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents--88767106-9edc-4028-a451-0da43b669d7f\n"
     ]
    }
   ],
   "source": [
    "#Note that the name of a bucket must be unique to all of S3 DNS namespace\n",
    "#Names can only start with [a-z0-9] but may include [a-z0-9-_./]\n",
    "\n",
    "#bucket_name = 'Documents' #this will fail\n",
    "#bucket_name = create_unique_name('') #this is safer\n",
    "#bucket_name = create_unique_name('documents'+'--'+str(uuid.uuid4())) #this is easier to directly work with\n",
    "\n",
    "bucket_name = 'documents--88767106-9edc-4028-a451-0da43b669d7f' #hardcode this so it doesnt change\n",
    "#bucket_name = 'testname.asyla.org'\n",
    "\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents--88767106-9edc-4028-a451-0da43b669d7f exists\n"
     ]
    }
   ],
   "source": [
    "if s3.Bucket(bucket_name).creation_date is None: #there is no date if it doesnt exist\n",
    "    response = create_bucket(bucket_name, s3)\n",
    "    print(response)\n",
    "else:\n",
    "    print (bucket_name + ' exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create/write to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01908f89-1998-4099-9117-f90eab55be20\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "documentID=str(uuid.uuid4())\n",
    "print(documentID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/19/40/91/f9/\n"
     ]
    }
   ],
   "source": [
    "#generate the path\n",
    "\n",
    "#couldnt get `re.sub()` to cooperate so did this instead\n",
    "\n",
    "import re\n",
    "\n",
    "path = ''\n",
    "\n",
    "for part in documentID.split('-'):\n",
    "    path += re.search('^.{2}', part).group(0) + '/' #match the first 2 chars and output the first match\n",
    "\n",
    "print (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/19/40/91/f9/01908f89-1998-4099-9117-f90eab55be20.yaml\n"
     ]
    }
   ],
   "source": [
    "file_name=documentID+'.yaml'\n",
    "key_name=path+file_name\n",
    "print(key_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "does_key_exist(bucket_name, key_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "2019-11-15 19:21:00+00:00\n",
      "{'test': 'this is a test'}\n"
     ]
    }
   ],
   "source": [
    "#find the size of the file\n",
    "#https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Object.content_length\n",
    "print (s3.Object(bucket_name, key_name).content_length)\n",
    "\n",
    "#last modified\n",
    "#https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Object.last_modified\n",
    "print (s3.Object(bucket_name, key_name).last_modified)\n",
    "\n",
    "#associated metadata\n",
    "#https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Object.metadata\n",
    "#NOTE: The actual `\"key\": \"value\"` pair would be `\"x-amz-meta-test\": \"this is a test\"` while here it would show as `\"test\": \"this is a test\"`\n",
    "print (s3.Object(bucket_name, key_name).metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\nmore text for the file\\n\\nhere is some text\\nhere is some text\\nhere is some text\\nhere is some text\\n'\n",
      "b'\\n\\nmore text for the file\\n\\nhere is some text\\nhere is some text\\nhere is some text\\nhere is some text\\nhere is some text\\n'\n"
     ]
    }
   ],
   "source": [
    "#download a file and append data to it\n",
    "\n",
    "import tempfile #https://docs.python.org/3/library/tempfile.html\n",
    "\n",
    "maxSize=1024*1024*10 #10MB\n",
    "\n",
    "tf = tempfile.SpooledTemporaryFile(max_size=maxSize) #create a temp file stored in memory or disk depending on size\n",
    "\n",
    "s3.Object(bucket_name, file_name).download_fileobj(tf) #download the file\n",
    "\n",
    "tf.seek(0) #goto the beginning of the file\n",
    "t=tf.read()\n",
    "print (t)\n",
    "\n",
    "tf.seek(0,2) #goto 0th byte before EOF:  https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects\n",
    "tf.write(b'here is some text\\n')\n",
    "\n",
    "tf.seek(0) #goto the beginning of the file\n",
    "t=tf.read()\n",
    "print (t)\n",
    "\n",
    "tf.seek(0) #goto the beginning of the file\n",
    "s3.Object(bucket_name, file_name).upload_fileobj(tf) #upload the file\n",
    "\n",
    "tf.close() #close/delete the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
